{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skopt import forest_minimize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, f1_score, accuracy_score, recall_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('./csv_files/featuresDF_cleaned.csv', index_col=0).dropna()\n",
    "target = features.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(['target','question_len'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval =  train_test_split(features, target,random_state=0, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numeric = Xtrain[['product_id']]\n",
    "val_numeric = Xval[['product_id']]\n",
    "\n",
    "train_text = Xtrain[['answers_cleaned','desc_cleaned','questions_cleaned']]\n",
    "val_text = Xval[['answers_cleaned','desc_cleaned','questions_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1,5))\n",
    "\n",
    "questions_bow_train = vectorizer.fit_transform(train_text.questions_cleaned)\n",
    "questions_bow_val = vectorizer.transform(val_text.questions_cleaned)\n",
    "\n",
    "answers_bow_train = vectorizer.fit_transform(train_text.answers_cleaned)\n",
    "answers_bow_val = vectorizer.transform(val_text.answers_cleaned)\n",
    "\n",
    "desc_bow_train = vectorizer.fit_transform(train_text.desc_cleaned)\n",
    "desc_bow_val = vectorizer.transform(val_text.desc_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_stack = hstack([questions_bow_train])\n",
    "Xval_stack = hstack([questions_bow_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=1000,random_state=0, class_weight='balanced')\n",
    "mdl.fit(Xtrain_stack, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf = mdl.predict(Xval_stack)\n",
    "proba_rf = mdl.predict_proba(Xval_stack)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.70      0.72       172\n",
      "         1.0       0.74      0.78      0.76       186\n",
      "\n",
      "    accuracy                           0.74       358\n",
      "   macro avg       0.74      0.74      0.74       358\n",
      "weighted avg       0.74      0.74      0.74       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,p_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8516816704176045, 0.8398157487041207)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval,proba), average_precision_score(yval,proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7397959183673469,\n",
       " 0.7795698924731183,\n",
       " 0.7591623036649214,\n",
       " 0.7430167597765364)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(yval,p_rf), recall_score(yval,p_rf), f1_score(yval,p_rf), accuracy_score(yval,p_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgbm(args):\n",
    "    ## Lgbm parametres\n",
    "    lr = args[0]\n",
    "    max_depth = args[1]\n",
    "    min_child_samples = args[2]\n",
    "    subsample = args[3]\n",
    "    colsample_bytree = args[4]\n",
    "    n_estimators = args[5]\n",
    "    \n",
    "    ## Tfidf parameters\n",
    "    min_df = args[6]\n",
    "    ngram_range = (1, args[7])\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    questions_bow_train = vectorizer.fit_transform(train_text.questions_cleaned)\n",
    "    questions_bow_val = vectorizer.transform(val_text.questions_cleaned)\n",
    "    \n",
    "    Xtrain_stack = hstack([train_numeric,questions_bow_train])\n",
    "    Xval_stack = hstack([val_numeric,questions_bow_val])\n",
    "    \n",
    "    mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                        min_child_samples=min_child_samples, subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree, bagging_freq=1, n_estimators=n_estimators,\n",
    "                        random_state=0, class_weight='balanced', n_jobs=6)\n",
    "    \n",
    "    mdl.fit(Xtrain_stack, ytrain)\n",
    "    \n",
    "    p = mdl.predict(Xval_stack)\n",
    "    proba = mdl.predict_proba(Xval_stack)[:,1]\n",
    "    \n",
    "    print(roc_auc_score(yval,proba))\n",
    "    \n",
    "    return -average_precision_score(yval, proba)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [(1e-3, 1e-1, 'log-uniform'), # lr\n",
    "          (1, 10), # max_depth\n",
    "          (1, 20), # min_child_samples\n",
    "          (0.05, 1.), # subsample\n",
    "          (0.05, 1.), # colsample_bytree\n",
    "          (100,1000), # n_estimators\n",
    "          (1,5), # min_df\n",
    "          (1,5)] # ngram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = forest_minimize(tune_lgbm, space, random_state=160745, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006187068367625307, 5, 3, 0.35655474283122957, 0.149808846705096, 925, 1, 1]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "lr = parameters[0]\n",
    "max_depth = parameters[1]\n",
    "min_child_samples = parameters[2]\n",
    "subsample = parameters[3]\n",
    "colsample_bytree = parameters[4]\n",
    "n_estimators = parameters[5]\n",
    "\n",
    "## Tfidf parameters\n",
    "min_df = parameters[6]\n",
    "ngram_range = (1, parameters[7])\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "\n",
    "questions_bow_train = vectorizer.fit_transform(train_text.questions_cleaned)\n",
    "questions_bow_val = vectorizer.transform(val_text.questions_cleaned)\n",
    "\n",
    "Xtrain_stack = hstack([questions_bow_train])\n",
    "Xval_stack = hstack([questions_bow_val])\n",
    "\n",
    "mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                    min_child_samples=min_child_samples, subsample=subsample,\n",
    "                    colsample_bytree=colsample_bytree, bagging_freq=1, n_estimators=n_estimators,\n",
    "                    random_state=0, class_weight='balanced', n_jobs=6)\n",
    "    \n",
    "mdl.fit(Xtrain_stack, ytrain)\n",
    "\n",
    "p_lgbm = mdl.predict(Xval_stack)\n",
    "proba_lgbm = mdl.predict_proba(Xval_stack)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7845555138784697, 0.7894329269058277)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval,proba_lgbm), average_precision_score(yval,proba_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8344827586206897,\n",
       " 0.6505376344086021,\n",
       " 0.7311178247734138,\n",
       " 0.7513966480446927)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(yval,p_lgbm), recall_score(yval,p_lgbm), f1_score(yval,p_lgbm), accuracy_score(yval,p_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.86      0.77       172\n",
      "         1.0       0.83      0.65      0.73       186\n",
      "\n",
      "    accuracy                           0.75       358\n",
      "   macro avg       0.76      0.76      0.75       358\n",
      "weighted avg       0.77      0.75      0.75       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,p_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text = str(text)\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', ' ', text)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def remove_stops(text):\n",
    "    clean = [word for word in text.split() if word.lower() not in stopwords.words('portuguese')]\n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_data(product_id,text):\n",
    "    text_clean = remove_stops(remove_punct(text))\n",
    "    text_list = [text_clean]\n",
    "    \n",
    "    dict_info = {\n",
    "        'product_id': [product_id],\n",
    "    }\n",
    "    numeric = pd.DataFrame(dict_info)\n",
    "    \n",
    "    print(text_list)\n",
    "    \n",
    "    text_vec = vectorizer.transform(text_list)\n",
    "    stack = hstack([numeric,text_vec])\n",
    "\n",
    "    p = mdl.predict(stack)\n",
    "    proba = mdl.predict_proba(stack)[:,1]\n",
    "    \n",
    "    print('Previsao:', p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entrada pen drive função trocar pastas manda link caixa descrições vc']\n",
      "Previsao: [1.]\n"
     ]
    }
   ],
   "source": [
    "predict_from_data(0,'Tem entrada para pen drive e se tem a função de trocar de pastas do mesmo? Se não tiver manda o link de uma caixa que tenha essas descrições. Se vc tiver.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Olá quero 3 unidades com fretes grátis para 29903082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsão para a pergunta:  1\n"
     ]
    }
   ],
   "source": [
    "x = [input()]\n",
    "x_vec = vectorizer.transform(x)\n",
    "p = mdl.predict(x_vec)\n",
    "\n",
    "print('Previsão para a pergunta: ', int(p[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
