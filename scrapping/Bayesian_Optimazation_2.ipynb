{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from skopt import forest_minimize\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, f1_score, accuracy_score, recall_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('./csv_files/featuresDF_cleaned.csv', index_col=0).dropna()\n",
    "target = features.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(['target','question_len'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval =  train_test_split(features, target,random_state=0, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numeric = Xtrain[['product_id']]\n",
    "val_numeric = Xval[['product_id']]\n",
    "\n",
    "train_text = Xtrain[['answers_cleaned','desc_cleaned','questions_cleaned']]\n",
    "val_text = Xval[['answers_cleaned','desc_cleaned','questions_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,1))\n",
    "\n",
    "questions_bow_train = vectorizer.fit_transform(train_text.questions_cleaned)\n",
    "questions_bow_val = vectorizer.transform(val_text.questions_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_stack = hstack([train_numeric,questions_bow_train])\n",
    "Xval_stack = hstack([val_numeric, questions_bow_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_rf = RandomForestClassifier(n_estimators=1000,random_state=0, class_weight='balanced')\n",
    "mdl_rf.fit(Xtrain_stack, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rf = mdl_rf.predict(Xval_stack)\n",
    "proba_rf = mdl_rf.predict_proba(Xval_stack)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.82      0.77       172\n",
      "         1.0       0.81      0.70      0.75       186\n",
      "\n",
      "    accuracy                           0.76       358\n",
      "   macro avg       0.76      0.76      0.76       358\n",
      "weighted avg       0.77      0.76      0.76       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,p_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8338334583645912, 0.8187160213884275)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval,proba), average_precision_score(yval,proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.808641975308642, 0.7043010752688172, 0.7528735632183908, 0.7597765363128491)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(yval,p_rf), recall_score(yval,p_rf), f1_score(yval,p_rf), accuracy_score(yval,p_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lgbm(args):\n",
    "    ## Lgbm parametres\n",
    "    lr = args[0]\n",
    "    max_depth = args[1]\n",
    "    min_child_samples = args[2]\n",
    "    subsample = args[3]\n",
    "    colsample_bytree = args[4]\n",
    "    n_estimators = args[5]\n",
    "    \n",
    "    ## Tfidf parameters\n",
    "    min_df = args[6]\n",
    "    ngram_range = (1, args[7])\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    questions_bow_train = vectorizer.fit_transform(train_text.questions_cleaned)\n",
    "    questions_bow_val = vectorizer.transform(val_text.questions_cleaned)\n",
    "    \n",
    "    Xtrain_stack = hstack([train_numeric,questions_bow_train])\n",
    "    Xval_stack = hstack([val_numeric,questions_bow_val])\n",
    "    \n",
    "    mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                        min_child_samples=min_child_samples, subsample=subsample,\n",
    "                        colsample_bytree=colsample_bytree, bagging_freq=1, n_estimators=n_estimators,\n",
    "                        random_state=0, class_weight='balanced', n_jobs=6)\n",
    "    \n",
    "    mdl.fit(Xtrain_stack, ytrain)\n",
    "    \n",
    "    p = mdl.predict(Xval_stack)\n",
    "    proba = mdl.predict_proba(Xval_stack)[:,1]\n",
    "    \n",
    "    print(roc_auc_score(yval,proba))\n",
    "    \n",
    "    return -average_precision_score(yval, proba)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [(1e-3, 1e-1, 'log-uniform'), # lr\n",
    "          (1, 10), # max_depth\n",
    "          (1, 20), # min_child_samples\n",
    "          (0.05, 1.), # subsample\n",
    "          (0.05, 1.), # colsample_bytree\n",
    "          (100,1000), # n_estimators\n",
    "          (1,5), # min_df\n",
    "          (1,5)] # ngram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = forest_minimize(tune_lgbm, space, random_state=160745, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006187068367625307, 5, 3, 0.35655474283122957, 0.149808846705096, 925, 1, 1]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/√Årea de Trabalho/venvs/jupyter/lib/python3.6/site-packages/lightgbm/basic.py:546: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "# Best parameters\n",
    "lr = parameters[0]\n",
    "max_depth = parameters[1]\n",
    "min_child_samples = parameters[2]\n",
    "subsample = parameters[3]\n",
    "colsample_bytree = parameters[4]\n",
    "n_estimators = parameters[5]\n",
    "\n",
    "## Tfidf parameters\n",
    "min_df = parameters[6]\n",
    "ngram_range = (1, parameters[7])\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "\n",
    "questions_bow_train = vectorizer.fit_transform(train_text.questions_cleaned)\n",
    "questions_bow_val = vectorizer.transform(val_text.questions_cleaned)\n",
    "\n",
    "Xtrain_stack = hstack([train_numeric,questions_bow_train])\n",
    "Xval_stack = hstack([val_numeric,questions_bow_val])\n",
    "\n",
    "mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                    min_child_samples=min_child_samples, subsample=subsample,\n",
    "                    colsample_bytree=colsample_bytree, bagging_freq=1, n_estimators=n_estimators,\n",
    "                    random_state=0, class_weight='balanced', n_jobs=6)\n",
    "    \n",
    "mdl.fit(Xtrain_stack, ytrain)\n",
    "\n",
    "p_lgbm = mdl.predict(Xval_stack)\n",
    "proba_lgbm = mdl.predict_proba(Xval_stack)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.807248687171793, 0.8040582502799695)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval,proba_lgbm), average_precision_score(yval,proba_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8113207547169812,\n",
       " 0.6935483870967742,\n",
       " 0.7478260869565218,\n",
       " 0.7569832402234636)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(yval,p_lgbm), recall_score(yval,p_lgbm), f1_score(yval,p_lgbm), accuracy_score(yval,p_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.83      0.77       172\n",
      "         1.0       0.81      0.69      0.75       186\n",
      "\n",
      "    accuracy                           0.76       358\n",
      "   macro avg       0.76      0.76      0.76       358\n",
      "weighted avg       0.76      0.76      0.76       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,p_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = 0.6* proba_lgbm + 0.4*proba_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8363497124281071, 0.8169057690634994)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval,proba), average_precision_score(yval,proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text = str(text)\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', ' ', text)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def remove_stops(text):\n",
    "    clean = [word for word in text.split() if word.lower() not in stopwords.words('portuguese')]\n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_data(product_id,text):\n",
    "    text_clean = remove_stops(remove_punct(text))\n",
    "    text_list = [text_clean]\n",
    "    \n",
    "    dict_info = {\n",
    "        'product_id': [product_id],\n",
    "    }\n",
    "    numeric = pd.DataFrame(dict_info)\n",
    "    \n",
    "    print(text_list)\n",
    "    \n",
    "    text_vec = vectorizer.transform(text_list)\n",
    "    stack = hstack([numeric,text_vec])\n",
    "\n",
    "    p = mdl.predict(stack)\n",
    "    proba = mdl.predict_proba(stack)[:,1]\n",
    "    \n",
    "    print('Previsao:', int(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comprar faz desconto']\n",
      "Previsao: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/√Årea de Trabalho/venvs/jupyter/lib/python3.6/site-packages/lightgbm/basic.py:546: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "predict_from_data(0,'Se eu comprar 10, faz desconto?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [input()]\n",
    "x_vec = vectorizer.transform(x)\n",
    "p = mdl.predict(x_vec)\n",
    "\n",
    "print('Previs√£o para a pergunta: ', int(p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/questions_vectorizer_20200502.pkl.z']"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.dump(mdl, \"./models/lgbm_20200502.pkl.z\")\n",
    "jb.dump(mdl_rf, \"./models/random_forest_20200502.pkl.z\")\n",
    "jb.dump(vectorizer, \"./models/questions_vectorizer_20200502.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
