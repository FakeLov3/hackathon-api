{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Concatenating Data (get foreign key data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./csv_files/edited_csv.csv\", index_col=0)\n",
    "df_sample = pd.read_csv(\"./csv_files/sample_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_json('./json_files/products_table.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_json = pd.read_json('./json_files/questions_table.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = questions_json[questions_json['id'].isin(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/√Årea de Trabalho/venvs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "questions_df['label'] = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.to_csv('./csv_files/questions_labeled_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = questions_df.reset_index().drop(['index','id','is_good','status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df['description'] = questions_df.product_id.map(lambda x: ' '.join(products[products['id']==x].description.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.to_csv('./csv_files/questions_first_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Words Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv('./csv_files/questions_first_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import string\n",
    "import re\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=questions_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['product_id'] = questions_df['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['question_len'] = questions_df.questions.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text = str(text)\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', ' ', text)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def remove_stops(text):\n",
    "    clean = [word for word in text.split() if word.lower() not in stopwords.words('portuguese')]\n",
    "    return ' '.join(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.questions = questions_df.questions.str.replace(',',' ')\n",
    "questions_df.answers = questions_df.answers.str.replace(',',' ')\n",
    "questions_df.description = questions_df.description.str.replace(',', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punct_questions = questions_df.questions.apply(remove_punct)\n",
    "no_punct_answers = questions_df.answers.apply(remove_punct)\n",
    "no_punct_desc = questions_df.description.apply(remove_punct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_questions = no_punct_questions.apply(remove_stops)\n",
    "no_stop_answers = no_punct_answers.apply(remove_stops)\n",
    "no_stop_desc = no_punct_desc.apply(remove_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['questions_cleaned'] = no_stop_questions\n",
    "features['answers_cleaned'] = no_stop_answers\n",
    "features['desc_cleaned'] = no_stop_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['questions_cleaned_len'] = features.questions_cleaned.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['target'] = questions_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('./csv_files/featuresDF_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Vectorize strings field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vec = pd.DataFrame(index=features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = questions_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(features.drop('target',axis=1),target,random_state=0, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550, 6), (368, 6), (550,), (368,))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_train = Xtrain[['questions_cleaned', 'answers_cleaned', 'desc_cleaned']]\n",
    "strings_val = Xval[['questions_cleaned', 'answers_cleaned', 'desc_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2)\n",
    "\n",
    "questions_bow_train = vectorizer.fit_transform(strings_train.questions_cleaned)\n",
    "questions_bow_val = vectorizer.transform(strings_val.questions_cleaned)\n",
    "\n",
    "answers_bow_train = vectorizer.fit_transform(strings_train.answers_cleaned)\n",
    "answers_bow_val = vectorizer.transform(strings_val.answers_cleaned)\n",
    "\n",
    "desc_bow_train = vectorizer.fit_transform(strings_train.desc_cleaned)\n",
    "desc_bow_val = vectorizer.transform(strings_val.desc_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_noStrings = Xtrain.drop(strings_train,axis=1)\n",
    "Xval_noStrings = Xval.drop(strings_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_wBows = hstack([Xtrain_noStrings, questions_bow_train, answers_bow_train, desc_bow_train])\n",
    "Xval_wBows = hstack([Xval_noStrings, questions_bow_val, answers_bow_val, desc_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('./npz/features_bow_train.npz', Xtrain_wBows)\n",
    "scipy.sparse.save_npz('./npz/features_bow_val.npz', Xval_wBows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_qBow = hstack([Xtrain_noStrings, questions_bow_train])\n",
    "Xval_qBow = hstack([Xval_noStrings, questions_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('./npz/features_questions_train.npz', Xtrain_qBow)\n",
    "scipy.sparse.save_npz('./npz/features_questions_vak.npz', Xval_qBow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 - Model 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Rando Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=1000,random_state=0, class_weight='balanced')\n",
    "mdl.fit(Xtrain_qBow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict(Xval_qBow)\n",
    "proba = mdl.predict_proba(Xval_qBow)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.64      0.73       176\n",
      "         1.0       0.73      0.89      0.80       192\n",
      "\n",
      "    accuracy                           0.77       368\n",
      "   macro avg       0.78      0.76      0.76       368\n",
      "weighted avg       0.78      0.77      0.76       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176   0]\n",
      " [  0 192]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yval,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval,proba), average_precision_score(yval,proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(yval,p), recall_score(yval,p), f1_score(yval,p), accuracy_score(yval,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = make_pipeline(MaxAbsScaler(), LogisticRegression(C=0.5, penalty='l2', n_jobs=6, random_state=0))\n",
    "lr_pipeline.fit(Xtrain_qBow,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lr = lr_pipeline.predict(Xval_qBow)\n",
    "proba_lr = lr_pipeline.predict_proba(Xval_qBow)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(yval,p_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(yval,proba_lr), average_precision_score(yval,proba_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(yval,p_lr), recall_score(yval,p_lr), f1_score(yval,p_lr), accuracy_score(yval,p_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state=0, class_weight='balanced')\n",
    "lgbm.fit(Xtrain_qBow, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lgbm = lgbm.predict(Xval_qBow)\n",
    "proba_lgbm = lgbm.predict_proba(Xval_qBow)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(yval,p_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(yval,proba_lgbm), average_precision_score(yval,proba_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(yval,p_lgbm), recall_score(yval,p_lgbm), f1_score(yval,p_lgbm), accuracy_score(yval,p_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
