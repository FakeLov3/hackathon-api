{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Concatenating Data (get foreign key data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./csv_files/edited_csv.csv\", index_col=0)\n",
    "df_sample = pd.read_csv(\"./csv_files/sample_cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_json('./json_files/products_table.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_json = pd.read_json('./json_files/questions_table.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = questions_json[questions_json['id'].isin(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinicius/√Årea de Trabalho/venvs/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "questions_df['label'] = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.to_csv('./csv_files/questions_labeled_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = questions_df.reset_index().drop(['index','id','is_good','status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df['description'] = questions_df.product_id.map(lambda x: ' '.join(products[products['id']==x].description.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.to_csv('./csv_files/questions_first_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Words Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv('./csv_files/questions_first_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import string\n",
    "import re\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=questions_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['product_id'] = questions_df['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['question_len'] = questions_df.questions.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text = str(text)\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', ' ', text)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def remove_stops(text):\n",
    "    clean = [word for word in text.split() if word.lower() not in stopwords.words('portuguese')]\n",
    "    return ' '.join(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.questions = questions_df.questions.str.replace(',',' ')\n",
    "questions_df.answers = questions_df.answers.str.replace(',',' ')\n",
    "questions_df.description = questions_df.description.str.replace(',', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punct_questions = questions_df.questions.apply(remove_punct)\n",
    "no_punct_answers = questions_df.answers.apply(remove_punct)\n",
    "no_punct_desc = questions_df.description.apply(remove_punct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_questions = no_punct_questions.apply(remove_stops)\n",
    "no_stop_answers = no_punct_answers.apply(remove_stops)\n",
    "no_stop_desc = no_punct_desc.apply(remove_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['questions_cleaned'] = no_stop_questions\n",
    "features['answers_cleaned'] = no_stop_answers\n",
    "features['desc_cleaned'] = no_stop_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['questions_cleaned_len'] = features.questions_cleaned.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('./csv_files/featuresDF_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Vectorize strings field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vec = pd.DataFrame(index=features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = questions_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(features,target,random_state=0, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((550, 6), (368, 6), (550,), (368,))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_train = Xtrain[['questions_cleaned', 'answers_cleaned', 'desc_cleaned']]\n",
    "strings_val = Xval[['questions_cleaned', 'answers_cleaned', 'desc_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2)\n",
    "\n",
    "questions_bow_train = vectorizer.fit_transform(strings_train.questions_cleaned)\n",
    "questions_bow_val = vectorizer.transform(strings_val.questions_cleaned)\n",
    "\n",
    "answers_bow_train = vectorizer.fit_transform(strings_train.answers_cleaned)\n",
    "answers_bow_val = vectorizer.transform(strings_val.answers_cleaned)\n",
    "\n",
    "desc_bow_train = vectorizer.fit_transform(strings_train.desc_cleaned)\n",
    "desc_bow_val = vectorizer.transform(strings_val.desc_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_noStrings = Xtrain.drop(strings_train,axis=1)\n",
    "Xval_noStrings = Xval.drop(strings_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_wBows = hstack([Xtrain_noStrings, questions_bow_train, answers_bow_train, desc_bow_train])\n",
    "Xval_wBows = hstack([Xval_noStrings, questions_bow_val, answers_bow_val, desc_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<550x3522 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 43496 stored elements in COOrdinate format>,\n",
       " <368x3522 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 27127 stored elements in COOrdinate format>)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_wBows, Xval_wBows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('./npz/features_bow_train.npz', Xtrain_wBows)\n",
    "scipy.sparse.save_npz('./npz/features_bow_val.npz', Xval_wBows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_qBow = hstack([Xtrain_noStrings, questions_bow_train])\n",
    "Xval_qBow = hstack([Xval_noStrings, questions_bow_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('./npz/features_questions_train.npz', Xtrain_qBow)\n",
    "scipy.sparse.save_npz('./npz/features_questions_vak.npz', Xval_qBow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 - Model 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RandomForestClassifier(n_estimators=1000,random_state=0, class_weight='balanced')\n",
    "mdl.fit(Xtrain_qBow,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict(Xval_qBow)\n",
    "proba = mdl.predict_proba(Xval_qBow)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.64      0.73       176\n",
      "         1.0       0.73      0.89      0.80       192\n",
      "\n",
      "    accuracy                           0.77       368\n",
      "   macro avg       0.78      0.76      0.76       368\n",
      "weighted avg       0.78      0.77      0.76       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yval,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15789240056818182, 0.3518864709453402)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yval,proba), average_precision_score(yval,proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7296137339055794, 0.8854166666666666)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(yval,p), recall_score(yval,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 - KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "X=df_edited.questions\n",
    "y=df_edited.label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
