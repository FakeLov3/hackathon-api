{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import requests as rq # http requests\n",
    "import bs4 as bs4 # beautiful soup for parsing\n",
    "from bs4 import BeautifulSoup\n",
    "import tqdm\n",
    "from os import listdir\n",
    "import glob\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['olist']\n",
    "n_pages = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pages = np.arange(1,(n_pages*48), 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  49,  97, 145])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://lista.mercadolivre.com.br/_Desde_{page}_Loja_olist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scrapping Pages\n",
    "for page in list_pages:\n",
    "    urll = url.format(page=page)\n",
    "    response = rq.get(urll)\n",
    "    with open(\"./raw_data/page_{}.html\".format(page),'w+') as output:\n",
    "        output.write(response.text)\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in list_pages:\n",
    "    with open('./raw_data/page_{}.html'.format(page),'r+') as inp:\n",
    "        page_html = inp.read()\n",
    "        parsed = bs4.BeautifulSoup(page_html)\n",
    "        tags = parsed.findAll('a', {\"class\": \"item-link item__js-link\"})\n",
    "        \n",
    "        for e in tags:\n",
    "            link = e['href']\n",
    "            title = e.find('img')['alt']\n",
    "\n",
    "            with open('parsed_products_links.json','a+') as output:\n",
    "                data = {'link':link,'title':title}\n",
    "                output.write('{}\\n'.format(json.dumps(data)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./parsed_products_links.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = df.link.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping products\n",
    "for i,link in enumerate(links):\n",
    "    urll = link\n",
    "    response = rq.get(urll)\n",
    "    with open(\"./raw_data_products/product_{}.html\".format(i),'w+') as output:\n",
    "        output.write(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parsed_product_info.json\",\"w+\") as output:\n",
    "    for product in tqdm.tqdm_notebook(sorted(glob.glob(\"./raw_data_products/product*\"))):\n",
    "        with open(product,\"r+\") as inp:\n",
    "            page_html = inp.read()\n",
    "            parsed = bs4.BeautifulSoup(page_html,\"html.parser\") \n",
    "            \n",
    "            questions = parsed.find_all('p', attrs={\"class\":'ui-pdp-color--BLACK ui-pdp-size--SMALL ui-pdp-family--REGULAR ui-pdp-qadb__questions-list__question__label'}) \n",
    "            print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import WebDriverException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = '/home/vinicius/Área de Trabalho/codes/megahack/raw_data_products/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOOP\n",
    "\n",
    "driver = webdriver.Chrome('/home/vinicius/Downloads/chromedriver_linux64/chromedriver')\n",
    "data = {\n",
    "    'title': [],\n",
    "    'questions': [],\n",
    "    'answers': [],\n",
    "    'time_answer': []\n",
    "}\n",
    "\n",
    "for file in sorted(listdir(image_source)):\n",
    "    filename = 'file://{}{}'.format(image_source,file)\n",
    "    driver.get(filename)\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"root-app\"]/div/div[2]/div[3]/div[1]/div[2]/div/div/div[3]/span').click()\n",
    "        soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "        #print(\"Catch on method 2\")\n",
    "    except Exception:\n",
    "        #print('Not catch on method 1, raising Exception Method')\n",
    "        try:\n",
    "            driver.find_element_by_xpath('/html/body/main/div[2]/div[1]/div[1]/section[5]/a').click()\n",
    "            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "            #print('Catch on method 2')\n",
    "        except:\n",
    "            #print('Not found questions on file {}'.format(filename))\n",
    "            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "\n",
    "    ## Here the page is full loaded\n",
    "    questions = soup.find_all('p', {'class': 'ui-pdp-color--BLACK ui-pdp-size--SMALL ui-pdp-family--REGULAR ui-pdp-qadb__questions-list__question__label'})\n",
    "    questions2 = soup.find_all('article', {'class': 'questions__item questions__item--question'})\n",
    "\n",
    "    answers = soup.find_all('p', {'class': 'ui-pdp-color--BLACK ui-pdp-size--SMALL ui-pdp-family--REGULAR ui-pdp-qadb__questions-list__answer-item__answer'})\n",
    "    answers2 = soup.find_all('article', {'class': 'questions__item questions__item--answer'})\n",
    "\n",
    "    time2 = soup.find_all('time', {'class':'questions__time'})\n",
    "    \n",
    "    product_name = soup.find_all('h1', {'class': 'ui-pdp-title'})\n",
    "    product_name2 = soup.find_all('header', {'class': 'item-title'})\n",
    "\n",
    "    for e in product_name2:\n",
    "        product_name2 = x.find('h1').text.strip()\n",
    "\n",
    "    if len(questions)>0 and len(answers)>0:\n",
    "        #print('cai no questions 1')\n",
    "        for question, answer in zip(questions, answers):\n",
    "            data['title'].append(product_name[0].text)\n",
    "            data['questions'].append(question.text)\n",
    "            data['answers'].append(answer.text)\n",
    "            data['time_answer'].append(None)\n",
    "\n",
    "    elif len(questions2) >0 and len(answers2) > 0:\n",
    "        #print('cai na questions 2')\n",
    "        for question, answer in zip(questions2,answers2):\n",
    "            data['title'].append(product_name2)\n",
    "            data['questions'].append(question.find('p').text)\n",
    "            data['answers'].append(answer.find('p').text)\n",
    "            data['time_answer'].append(answer.find('time').text.strip())\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_json('parsed_products_info.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = '/home/vinicius/Área de Trabalho/codes/megahack/raw_data_products/'\n",
    "file = 'product_137.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not catch on method 1, raising Exception Method\n",
      "Not found questions button on file file:///home/vinicius/Área de Trabalho/codes/megahack/raw_data_products/product_137.html\n",
      "cai na questions 2\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('/home/vinicius/Downloads/chromedriver_linux64/chromedriver')\n",
    "driver.get(filename)\n",
    "time.sleep(2)\n",
    "question_id = 0\n",
    "product_id = 0\n",
    "i = 0\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath('//*[@id=\"root-app\"]/div/div[2]/div[3]/div[1]/div[2]/div/div/div[3]/span').click()\n",
    "    soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "    print(\"Catch on method 2\")\n",
    "except Exception:\n",
    "    print('Not catch on method 1, raising Exception Method')\n",
    "    try:\n",
    "        driver.find_element_by_xpath('/html/body/main/div[2]/div[1]/div[1]/section[5]/a').click()\n",
    "        soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "        print('Catch on method 2')\n",
    "    except:\n",
    "        print('Not found questions button on file {}'.format(filename))\n",
    "        soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "        \n",
    "## Here the page is full loaded\n",
    "questions = soup.find_all('p', {'class': 'ui-pdp-color--BLACK ui-pdp-size--SMALL ui-pdp-family--REGULAR ui-pdp-qadb__questions-list__question__label'})\n",
    "questions2 = soup.find_all('article', {'class': 'questions__item questions__item--question'})\n",
    "\n",
    "answers = soup.find_all('p', {'class': 'ui-pdp-color--BLACK ui-pdp-size--SMALL ui-pdp-family--REGULAR ui-pdp-qadb__questions-list__answer-item__answer'})\n",
    "answers2 = soup.find_all('article', {'class': 'questions__item questions__item--answer'})\n",
    "\n",
    "product_name = soup.find_all('h1', {'class': 'ui-pdp-title'})\n",
    "product_name2 = soup.find_all('header', {'class': 'item-title'})\n",
    "\n",
    "description = soup.find_all('li', {'class': 'ui-pdp-features__item'})\n",
    "description2 = soup.find_all('div', {'class': 'item-description__text'})\n",
    "\n",
    "price = soup.find_all('div', {'class': 'ui-pdp-price mt-16 ui-pdp-price--size-large'})\n",
    "price2 = soup.find_all('fieldset', {'class': 'item-price'})\n",
    "\n",
    "for e in price:\n",
    "    price = e.find('span', {'class': 'price-tag-fraction'}).text\n",
    "    \n",
    "for e in price2:\n",
    "    cents = e.find('span', {'class':'price-tag-cents'})\n",
    "    \n",
    "    if cents:\n",
    "        price2 = '{}.{}'.format(e.find('span', {'class':'price-tag-fraction'}).text, e.find('span', {'class':'price-tag-cents'}).text)\n",
    "    else:\n",
    "        price2 = '{}'.format(e.find('span', {'class':'price-tag-fraction'}).text)\n",
    "        \n",
    "\n",
    "for e in product_name2:\n",
    "    product_name2 = e.find('h1').text.strip()\n",
    "\n",
    "description_list = []\n",
    "for e in info:\n",
    "    description_list.append(e.text)\n",
    "description = ' '.join(description_list)\n",
    "\n",
    "\n",
    "for e in desc:\n",
    "    description2 = e.text.strip()\n",
    "\n",
    "data_questions = {\n",
    "    'id': [],\n",
    "    'product_id': [],\n",
    "    'title': [],\n",
    "    'questions': [],\n",
    "    'status': [],\n",
    "    'answers': [],\n",
    "    'is_good': [],\n",
    "}\n",
    "\n",
    "data_products = {\n",
    "    \"id\": [], # primary key\n",
    "    \"name\": [], # string\n",
    "    \"quantity\": [], #int\n",
    "    \"size\": [], #tuple\n",
    "    \"color\": [], #list\n",
    "    \"price\": [], #float\n",
    "    \"weight\": [], #float\n",
    "    \"image\": [], #list\n",
    "    \"description\": [],\n",
    "}\n",
    "\n",
    "if len(product_name)>0:\n",
    "    data_products['id'].append(i)\n",
    "    data_products['name'].append(product_name[0].text)\n",
    "    data_products['quantity'].append(5) #valor generico\n",
    "    data_products['size'].append(None)\n",
    "    data_products['color'].append(None)\n",
    "    data_products['price'].append(price)\n",
    "    data_products['weight'].append(None)\n",
    "    data_products['image'].append(None)\n",
    "    data_products['description'].append(description)\n",
    "\n",
    "elif len(product_name2)>0:\n",
    "    data_products['id'].append(i)\n",
    "    data_products['name'].append(product_name2)\n",
    "    data_products['quantity'].append(5) #valor generico\n",
    "    data_products['size'].append(None)\n",
    "    data_products['color'].append(None)\n",
    "    data_products['price'].append(price2)\n",
    "    data_products['weight'].append(None)\n",
    "    data_products['image'].append(None)\n",
    "    data_products['description'].append(description2)\n",
    "    \n",
    "\n",
    "\n",
    "## Save Questions Info\n",
    "if len(questions)>0 and len(answers)>0:\n",
    "    print('cai no questions 1')\n",
    "    for question, answer in zip(questions, answers):\n",
    "        data_questions['id'].append(question_id)\n",
    "        data_questions['product_id'].append(product_id)\n",
    "        data_questions['questions'].append(question.text)\n",
    "        data_questions['answers'].append(answer.text)\n",
    "        data_questions['is_good'].append(np.nan)\n",
    "        data_questions['status'].append('manual')\n",
    "        \n",
    "        question_id+=1\n",
    "        \n",
    "elif len(questions2) >0 and len(answers2) > 0:\n",
    "    print('cai na questions 2')\n",
    "    for question, answer in zip(questions2,answers2):\n",
    "        data_questions['id'].append(question_id)\n",
    "        data_questions['product_id'].append(product_id)\n",
    "        data_questions['questions'].append(question.find('p').text)\n",
    "        data_questions['answers'].append(answer.find('p').text)\n",
    "        data_questions['is_good'].append(np.nan)\n",
    "        data_questions['status'].append('manual')\n",
    "        \n",
    "        question_id+=1\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/home/vinicius/Downloads/chromedriver_linux64/chromedriver')\n",
    "data_questions = {\n",
    "    'id': [],\n",
    "    'product_id': [],\n",
    "    'questions': [],\n",
    "    'status': [],\n",
    "    'answers': [],\n",
    "    'is_good': [],\n",
    "}\n",
    "\n",
    "data_products = {\n",
    "    \"id\": [], # primary key\n",
    "    \"name\": [], # string\n",
    "    \"quantity\": [], #int\n",
    "    \"size\": [], #tuple\n",
    "    \"color\": [], #list\n",
    "    \"price\": [], #float\n",
    "    \"weight\": [], #float\n",
    "    \"image\": [], #list\n",
    "    \"description\": [],\n",
    "}\n",
    "question_id = 0\n",
    "\n",
    "\n",
    "for i,file in enumerate(sorted(listdir(image_source))):\n",
    "    filename = 'file://{}{}'.format(image_source,file)\n",
    "    driver.get(filename)\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"root-app\"]/div/div[2]/div[3]/div[1]/div[2]/div/div/div[3]/span').click()\n",
    "        soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "        print(\"Catch on method 2\")\n",
    "    except Exception:\n",
    "        print('Not catch on method 1, raising Exception Method')\n",
    "        try:\n",
    "            driver.find_element_by_xpath('/html/body/main/div[2]/div[1]/div[1]/section[5]/a').click()\n",
    "            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "            print('Catch on method 2')\n",
    "        except:\n",
    "            print('Not found questions button on file {}'.format(filename))\n",
    "            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "\n",
    "    ## Here the page is full loaded\n",
    "    questions = soup.find_all('p', {'class': 'ui-pdp-color--BLACK ui-pdp-size--SMALL ui-pdp-family--REGULAR ui-pdp-qadb__questions-list__question__label'})\n",
    "    questions2 = soup.find_all('article', {'class': 'questions__item questions__item--question'})\n",
    "\n",
    "    answers = soup.find_all('p', {'class': 'ui-pdp-color--BLACK ui-pdp-size--SMALL ui-pdp-family--REGULAR ui-pdp-qadb__questions-list__answer-item__answer'})\n",
    "    answers2 = soup.find_all('article', {'class': 'questions__item questions__item--answer'})\n",
    "\n",
    "    product_name = soup.find_all('h1', {'class': 'ui-pdp-title'})\n",
    "    product_name2 = soup.find_all('header', {'class': 'item-title'})\n",
    "\n",
    "    description = soup.find_all('li', {'class': 'ui-pdp-features__item'})\n",
    "    description2 = soup.find_all('div', {'class': 'item-description__text'})\n",
    "\n",
    "    price = soup.find_all('div', {'class': 'ui-pdp-price mt-16 ui-pdp-price--size-large'})\n",
    "    price2 = soup.find_all('fieldset', {'class': 'item-price'})\n",
    "\n",
    "    for e in price:\n",
    "        price = e.find('span', {'class': 'price-tag-fraction'}).text\n",
    "\n",
    "    for e in price2:\n",
    "        cents = e.find('span', {'class':'price-tag-cents'})\n",
    "\n",
    "        if cents:\n",
    "            price2 = '{}.{}'.format(e.find('span', {'class':'price-tag-fraction'}).text, e.find('span', {'class':'price-tag-cents'}).text)\n",
    "        else:\n",
    "            price2 = '{}'.format(e.find('span', {'class':'price-tag-fraction'}).text)\n",
    "\n",
    "    for e in product_name2:\n",
    "        product_name2 = e.find('h1').text.strip()\n",
    "\n",
    "    description_list = []\n",
    "    for e in info:\n",
    "        description_list.append(e.text)\n",
    "    description = ' '.join(description_list)\n",
    "\n",
    "\n",
    "    for e in desc:\n",
    "        description2 = e.text.strip()\n",
    "\n",
    "\n",
    "    if len(product_name)>0:\n",
    "        data_products['id'].append(i)\n",
    "        data_products['name'].append(product_name[0].text)\n",
    "        data_products['quantity'].append(None) #valor generico\n",
    "        data_products['size'].append(None)\n",
    "        data_products['color'].append(None)\n",
    "        data_products['price'].append(price)\n",
    "        data_products['weight'].append(None)\n",
    "        data_products['image'].append(None)\n",
    "        data_products['description'].append(description)\n",
    "\n",
    "    elif len(product_name2)>0:\n",
    "        data_products['id'].append(i)\n",
    "        data_products['name'].append(product_name2)\n",
    "        data_products['quantity'].append(None) \n",
    "        data_products['size'].append(None)\n",
    "        data_products['color'].append(None)\n",
    "        data_products['price'].append(price2)\n",
    "        data_products['weight'].append(None)\n",
    "        data_products['image'].append(None)\n",
    "        data_products['description'].append(description2)\n",
    "\n",
    "\n",
    "\n",
    "    ## Save Questions Info\n",
    "    if len(questions)>0 and len(answers)>0:\n",
    "        print('cai no questions 1')\n",
    "        for question, answer in zip(questions, answers):\n",
    "            data_questions['id'].append(question_id)\n",
    "            data_questions['product_id'].append(i)\n",
    "            data_questions['questions'].append(question.text)\n",
    "            data_questions['answers'].append(answer.text)\n",
    "            data_questions['is_good'].append(np.nan)\n",
    "            data_questions['status'].append('manual')\n",
    "\n",
    "            question_id+=1\n",
    "\n",
    "    elif len(questions2) >0 and len(answers2) > 0:\n",
    "        print('cai na questions 2')\n",
    "        for question, answer in zip(questions2,answers2):\n",
    "            data_questions['id'].append(question_id)\n",
    "            data_questions['product_id'].append(i)\n",
    "            data_questions['questions'].append(question.find('p').text)\n",
    "            data_questions['answers'].append(answer.find('p').text)\n",
    "            data_questions['is_good'].append(np.nan)\n",
    "            data_questions['status'].append('manual')\n",
    "\n",
    "            question_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.DataFrame(data_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = pd.DataFrame(data_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.to_json('products_table.json', orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions.to_json('questions_table.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
